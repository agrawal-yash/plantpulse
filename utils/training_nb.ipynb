{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nPlant Disease Detection with Balanced ViT + Augmentation\n\"\"\"\n\n# ===========================================================================\n# Step 1: Install Dependencies\n# ===========================================================================\n!pip install transformers torchvision opencv-python-headless imbalanced-learn --quiet\n\n# ===========================================================================\n# Step 2: Dataset Preparation & Balancing\n# ===========================================================================\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom torchvision import transforms, datasets\nfrom imblearn.over_sampling import RandomOverSampler\nimport torch\nfrom torch.utils.data import WeightedRandomSampler, DataLoader\n\n# Dataset paths\nBASE_PATH = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\nTRAIN_DIR = os.path.join(BASE_PATH, \"train\")\nVALID_DIR = os.path.join(BASE_PATH, \"valid\")\n\n# Calculate class weights\ndef get_class_weights(dataset):\n    class_counts = torch.bincount(torch.tensor(dataset.targets))\n    class_weights = 1. / class_counts.float()\n    return class_weights\n\n# ===========================================================================\n# Step 3: Enhanced Data Augmentation\n# ===========================================================================\nclass GaborFilterTransform:\n    def __init__(self, ksize=31, sigma=4.0, theta=np.pi/4, lambd=10.0, gamma=0.5):\n        self.ksize = ksize\n        self.sigma = sigma\n        self.theta = theta\n        self.lambd = lambd\n        self.gamma = gamma\n\n    def __call__(self, img):\n        img_np = np.array(img)\n        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n        kernel = cv2.getGaborKernel(\n            (self.ksize, self.ksize),\n            self.sigma,\n            self.theta,\n            self.lambd,\n            self.gamma,\n            0, cv2.CV_32F\n        )\n        filtered = cv2.filter2D(gray, cv2.CV_32F, kernel)\n        filtered = cv2.normalize(filtered, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n        return Image.fromarray(cv2.cvtColor(filtered, cv2.COLOR_GRAY2RGB))\n\n# Augmentation transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(30),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    GaborFilterTransform(theta=np.pi/4),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n    transforms.RandomCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    GaborFilterTransform(theta=np.pi/4),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# ===========================================================================\n# Step 4: Load and Balance Dataset\n# ===========================================================================\n# Load datasets\ntrain_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\nval_dataset = datasets.ImageFolder(VALID_DIR, transform=val_transform)\n\n# Calculate class weights and create sampler\nclass_weights = get_class_weights(train_dataset)\nsamples_weights = class_weights[train_dataset.targets]\nsampler = WeightedRandomSampler(\n    weights=samples_weights,\n    num_samples=len(samples_weights),\n    replacement=True\n)\n\n# ===========================================================================\n# Step 5: Model Setup with Hyperparameters\n# ===========================================================================\nfrom transformers import ViTForImageClassification\n\n# Hyperparameters\nBATCH_SIZE = 32\nLR = 3e-5\nEPOCHS = 10\nPATIENCE = 3  # For early stopping\n\n# Dataloaders\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=4\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4\n)\n\n# Initialize ViT\nmodel = ViTForImageClassification.from_pretrained(\n    'google/vit-base-patch16-224-in21k',\n    num_labels=38,\n    ignore_mismatched_sizes=True\n)\n\n# ===========================================================================\n# Step 6: Training with Optimization\n# ===========================================================================\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom sklearn.metrics import balanced_accuracy_score\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\ncriterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=1)\n\nbest_acc = 0\nno_improve = 0\n\nfor epoch in range(EPOCHS):\n    # Training\n    model.train()\n    train_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images).logits\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n    # Validation\n    model.eval()\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).logits\n            val_preds.extend(outputs.argmax(1).cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n    \n    # Calculate balanced accuracy\n    balanced_acc = balanced_accuracy_score(val_labels, val_preds)\n    print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | Val Acc: {balanced_acc:.2%}\")\n\n    # Early stopping & model checkpoint\n    if balanced_acc > best_acc:\n        best_acc = balanced_acc\n        no_improve = 0\n        torch.save(model.state_dict(), 'best_model.pth')\n    else:\n        no_improve += 1\n        if no_improve >= PATIENCE:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    scheduler.step(balanced_acc)\n\n# ===========================================================================\n# Step 7: Save Final Model\n# ===========================================================================\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'class_to_idx': train_dataset.class_to_idx,\n    'transform': train_transform,\n}, 'plant_disease_vit.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:46:04.034471Z","iopub.execute_input":"2025-04-03T16:46:04.03485Z","iopub.status.idle":"2025-04-03T20:46:29.937176Z","shell.execute_reply.started":"2025-04-03T16:46:04.03482Z","shell.execute_reply":"2025-04-03T20:46:29.936226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}