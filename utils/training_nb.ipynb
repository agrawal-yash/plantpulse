{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:46:04.03485Z",
     "iopub.status.busy": "2025-04-03T16:46:04.034471Z",
     "iopub.status.idle": "2025-04-03T20:46:29.937176Z",
     "shell.execute_reply": "2025-04-03T20:46:29.936226Z",
     "shell.execute_reply.started": "2025-04-03T16:46:04.03482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Plant Disease Detection with Balanced ViT + Augmentation\n",
    "\"\"\"\n",
    "\n",
    "# ===========================================================================\n",
    "# Step 1: Install Dependencies\n",
    "# ===========================================================================\n",
    "!pip install transformers torchvision opencv-python-headless imbalanced-learn --quiet\n",
    "\n",
    "# ===========================================================================\n",
    "# Step 2: Dataset Preparation & Balancing\n",
    "# ===========================================================================\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "\n",
    "# Dataset paths\n",
    "BASE_PATH = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "TRAIN_DIR = os.path.join(BASE_PATH, \"train\")\n",
    "VALID_DIR = os.path.join(BASE_PATH, \"valid\")\n",
    "\n",
    "# Calculate class weights\n",
    "def get_class_weights(dataset):\n",
    "    class_counts = torch.bincount(torch.tensor(dataset.targets))\n",
    "    class_weights = 1. / class_counts.float()\n",
    "    return class_weights\n",
    "\n",
    "# ===========================================================================\n",
    "# Step 3: Enhanced Data Augmentation\n",
    "# ===========================================================================\n",
    "class GaborFilterTransform:\n",
    "    def __init__(self, ksize=31, sigma=4.0, theta=np.pi/4, lambd=10.0, gamma=0.5):\n",
    "        self.ksize = ksize\n",
    "        self.sigma = sigma\n",
    "        self.theta = theta\n",
    "        self.lambd = lambd\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "        kernel = cv2.getGaborKernel(\n",
    "            (self.ksize, self.ksize),\n",
    "            self.sigma,\n",
    "            self.theta,\n",
    "            self.lambd,\n",
    "            self.gamma,\n",
    "            0, cv2.CV_32F\n",
    "        )\n",
    "        filtered = cv2.filter2D(gray, cv2.CV_32F, kernel)\n",
    "        filtered = cv2.normalize(filtered, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        return Image.fromarray(cv2.cvtColor(filtered, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "# Augmentation transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    GaborFilterTransform(theta=np.pi/4),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    GaborFilterTransform(theta=np.pi/4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ===========================================================================\n",
    "# Step 4: Load and Balance Dataset\n",
    "# ===========================================================================\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(VALID_DIR, transform=val_transform)\n",
    "\n",
    "# Calculate class weights and create sampler\n",
    "class_weights = get_class_weights(train_dataset)\n",
    "samples_weights = class_weights[train_dataset.targets]\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=samples_weights,\n",
    "    num_samples=len(samples_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# ===========================================================================\n",
    "# Step 5: Model Setup with Hyperparameters\n",
    "# ===========================================================================\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LR = 3e-5\n",
    "EPOCHS = 10\n",
    "PATIENCE = 3  # For early stopping\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "# Initialize ViT\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k',\n",
    "    num_labels=38,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# ===========================================================================\n",
    "# Step 6: Training with Optimization\n",
    "# ===========================================================================\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=1)\n",
    "\n",
    "best_acc = 0\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate balanced accuracy\n",
    "    balanced_acc = balanced_accuracy_score(val_labels, val_preds)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | Val Acc: {balanced_acc:.2%}\")\n",
    "\n",
    "    # Early stopping & model checkpoint\n",
    "    if balanced_acc > best_acc:\n",
    "        best_acc = balanced_acc\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    scheduler.step(balanced_acc)\n",
    "\n",
    "# ===========================================================================\n",
    "# Step 7: Save Final Model\n",
    "# ===========================================================================\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_to_idx': train_dataset.class_to_idx,\n",
    "    'transform': train_transform,\n",
    "}, 'plant_disease_vit.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
